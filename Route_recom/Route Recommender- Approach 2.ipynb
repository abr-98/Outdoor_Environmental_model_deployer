{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Initializing Gmap Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gmaps = googlemaps.Client(key='AIzaSyAr8OUoyTH5mDIuvnoXTdXHM9i2Jzeo7iU')\n",
    "\n",
    "### Currently Deactivated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dividing the whole city in NxN divisions\n",
    "\n",
    "#### Currently N=16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Left Down   ### End Right up\n",
    "START_LONG=87.269568\n",
    "START_LAT=23.534924\n",
    "END_LONG=87.321653\n",
    "END_LAT=23.565774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Creating Division\n",
    "def create_divisions(N):\n",
    "    Y_Axis=np.linspace(START_LAT,END_LAT,N)\n",
    "    X_Axis=np.linspace(START_LONG,END_LONG,N)\n",
    "    Longitudes,Latitudes=np.meshgrid(X_Axis,Y_Axis)\n",
    "    df_lat_long=pd.DataFrame(list(zip(Latitudes.flatten(),Longitudes.flatten())),columns=['Latitudes','Longitudes'])\n",
    "    return df_lat_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Fetching lat,long from location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_long(location):\n",
    "    #lat,long=tuple(gmaps.geocode(address=location))\n",
    "    \n",
    "    lat,long=23.555 ,87.29 ## Defined for testing\n",
    "    return lat,long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating Distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Euclidean distance calculated\n",
    "def euclidean_distance(x1,y1,x2,y2):\n",
    "    return ((x1-x2)**2+(y1-y2)**2)**0.5\n",
    "\n",
    "### Calculated distance from maps   ####Currently deactivated\n",
    "def transport_distance(lat1,long1,lat2,long2,mode=\"driving\"):\n",
    "    directions_result = gmaps.directions((lat1,long1),(lat2,long2),mode=mode)\n",
    "    return float(directions_result[0]['legs'][0]['distance']['text'].split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Euclidean distance + tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dummy: returns tuples list\n",
    "### In defn: POINTS (X1,Y1) and (X2,Y2)\n",
    "### CHECK THE PARAMETER PASSING\n",
    "INTERMIDIATE_TUPLES=5\n",
    "def return_tuples(x1,y1,x2,y2):\n",
    "    list_to_return=[]\n",
    "    axis_Y=np.linspace(x1,x2,INTERMIDIATE_TUPLES)    ##Latitudes\n",
    "    axis_X=np.linspace(y1,y2,INTERMIDIATE_TUPLES)    ##Longitudes\n",
    "    for index in range(len(axis_Y)):\n",
    "        list_to_return.append((axis_Y[index],axis_X[index]))\n",
    "    list_to_return.reverse()\n",
    "    \n",
    "    return list_to_return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### POINTS (X1,X2) and (Y1,Y2)\n",
    "### Dummy Tuple Creater and distance\n",
    "def euc_dist_plus_tuples(x1,y1,x2,y2):\n",
    "\n",
    "    dist=euclidean_distance(x1,x2,y1,y2)\n",
    "    tup_list=return_tuples(x1,x2,y1,y2)\n",
    "    \n",
    "    return dist,tup_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining Goal state and reward column from pollution prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Passing pollution_prediction\n",
    "### Passing N-no.of divisions: Help to provide granularity control\n",
    "### Passing Destination\n",
    "def add_reward_pollution_column(pollution_prediction,N,destination):\n",
    "    df_lat_long=create_divisions(N)\n",
    "    dest_lat,dest_long=get_lat_long(destination)\n",
    "    GOAL_STATE=np.argmin(df_lat_long[['Latitudes','Longitudes']].apply(lambda tup: euclidean_distance(tup[0],tup[1],dest_lat,dest_long),axis=1).values)\n",
    "    #### Goal state defined\n",
    "    df_lat_long['Pol_rewards']=-1*(np.array((PIL.Image.fromarray(pollution_prediction)).resize((N,N),PIL.Image.NEAREST)).flatten())\n",
    "    #### For ubuntu: If Error Use this:\n",
    "    #df_lat_long['Pol_rewards']=-1*(np.array((PIL.Image.fromarray(pollution_prediction)).astype(np.uint8).fromarray(arr)).resize((N,N),PIL.Image.NEAREST)).flatten())\n",
    "    ### Defined \n",
    "    df_lat_long.loc[GOAL_STATE,'Pol_rewards']=10\n",
    "    ## Defined goal state rewards\n",
    "    return df_lat_long\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS=8  ## Defining actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Providing movements according to actions\n",
    "## 0-> i, j+1 (right)\n",
    "## 1-> i+1,j+1 (diagonal upper)\n",
    "## 2-> i+1,j (up)\n",
    "## 3-> i+1,j-1 (left up diagonal)\n",
    "## 4-> i,j-1 (left)\n",
    "## 5-> i-1,j-1 (left right diagonal)\n",
    "## 6-> i-1,j (down)\n",
    "## 7-> i-1,j+1 (down,right)\n",
    "def get_move(action,position):\n",
    "    if action==0:\n",
    "        return (position[0],position[1]+1)\n",
    "    if action==1:\n",
    "        return (position[0]+1,position[1]+1)\n",
    "    if action==2:\n",
    "        return (position[0]+1,position[1])\n",
    "    if action==3:\n",
    "        return (position[0]+1,position[1]-1)\n",
    "    if action==4:\n",
    "        return (position[0],position[1]-1)\n",
    "    if action==5:\n",
    "        return (position[0]-1,position[1]-1)\n",
    "    if action==6:\n",
    "        return (position[0]-1,position[1])\n",
    "    if action==7:\n",
    "        return (position[0]-1,position[1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initializing all points details \n",
    "### Df_matrix columns= ['Index_Lat','Index_Long','Id','directions']\n",
    "### Df_df_state_details=['Latitudes','Longitudes','Pollution_based_rewards']\n",
    "def init_all_details(pollution_prediction,N,destination):\n",
    "    df_state_details=add_reward_pollution_column(pollution_prediction,N,destination)\n",
    "    matrix=[]  \n",
    "    index=0\n",
    "    for i in range(0,N):\n",
    "        for j in range(0,N):\n",
    "            point_det=[i]\n",
    "            point_det.append(j)\n",
    "            point_det.append(N*i+j)\n",
    "            map_directions={}\n",
    "            for action in range(ACTIONS):\n",
    "                map_directions[action]={}\n",
    "                map_directions[action]['id']=N*i+j\n",
    "                map_directions[action]['cord']=get_move(action,(i,j))\n",
    "                map_directions[action]['distance']=0\n",
    "                map_directions[action]['Tuples_list']=[]\n",
    "                map_directions[action]['cost']=df_state_details.iloc[index]['Pol_rewards']\n",
    "            point_det.append(map_directions)\n",
    "            index+=1\n",
    "            matrix.append(point_det)\n",
    "    df_matrix=pd.DataFrame(matrix,columns=['Index_Lat','Index_Long','Id','directions'])\n",
    "    df_state_details=pd.concat([df_matrix,df_state_details],axis=1)\n",
    "    \n",
    "    return df_state_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating Proper point details\n",
    "### Alpha is the weightage controlling parameter.\n",
    "def get_all_details(pollution_prediction,N,destination,alpha):\n",
    "    df_state_details=init_all_details(pollution_prediction,N,destination)\n",
    "    index=0\n",
    "    travel_cost=[]\n",
    "    pollution_cost=[]\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            mapping=df_state_details.iloc[index]['directions']\n",
    "            for action in range(ACTIONS):\n",
    "                x_cord,y_cord=((df_state_details.iloc[index]['directions'])[action])['cord']\n",
    "                if x_cord<0 or y_cord<0 or x_cord>N-1 or y_cord>N-1:\n",
    "                    travel_cost.append(0)\n",
    "                    pollution_cost.append(0)\n",
    "                    continue\n",
    "                \n",
    "                target_index=df_state_details[(df_state_details['Index_Lat']==x_cord) & (df_state_details['Index_Long']==y_cord)].iloc[0]['Id']\n",
    "                mapping[action]['id']=target_index\n",
    "                distance,tuples=euc_dist_plus_tuples(df_state_details.iloc[target_index]['Latitudes'],df_state_details.iloc[index]['Latitudes'],df_state_details.iloc[target_index]['Longitudes'],df_state_details.iloc[index]['Longitudes'])\n",
    "                mapping[action]['Tuples_list']=tuples\n",
    "                travel_cost.append(distance)\n",
    "                pollution_cost.append(df_state_details.iloc[target_index]['Pol_rewards'])\n",
    "            df_state_details.iloc[index]['directions']=mapping\n",
    "            index+=1\n",
    "    travel_cost=np.array(travel_cost)\n",
    "    pollution_cost=np.array(pollution_cost)\n",
    "    index=0\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            mapping=df_state_details.iloc[N*i+j]['directions']\n",
    "            for action in range(ACTIONS):\n",
    "                if travel_cost[index]==0:\n",
    "                    index+=1\n",
    "                    continue\n",
    "                mapping[action]['distance']=travel_cost[index]\n",
    "                mapping[action]['cost']=alpha*(-(travel_cost[index]-np.min(travel_cost))/(np.max(travel_cost)-np.min(travel_cost)))+(1-alpha)*((pollution_cost[index]-np.min(pollution_cost))/(np.max(pollution_cost)-np.min(pollution_cost)))\n",
    "                index+=1\n",
    "            df_state_details.iloc[N*i+j]['directions']=mapping\n",
    "            \n",
    "            \n",
    "    return df_state_details              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ALGORITHM\n",
    "def policy_iteration(P,R,STATES):\n",
    "    Q=np.zeros((ACTIONS,STATES,1))\n",
    "    Q_bk=np.random.random((ACTIONS,STATES,1))\n",
    "    V=np.zeros((STATES,1))\n",
    "    gamma=0.999\n",
    "    while(np.abs(Q-Q_bk).sum()>0.000001):\n",
    "        Q_bk=Q.copy()\n",
    "        Q=R+gamma*np.matmul(P,V)\n",
    "        policy=np.argmax(Q,axis=0)\n",
    "        V=np.max(Q,axis=0)\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALGORITHM EXECUTER\n",
    "def return_policy(pollution_prediction,destination,N,alpha):\n",
    "    df_state_details=get_all_details(pollution_prediction,N,destination,alpha)\n",
    "    STATES=len(df_state_details)\n",
    "    P=np.zeros((ACTIONS,STATES,STATES))\n",
    "    R=np.zeros((ACTIONS,STATES,1))\n",
    "    for state in range(STATES):\n",
    "        mapping=df_state_details.iloc[state]['directions']\n",
    "        for action in range(ACTIONS):   \n",
    "            P[action,state,mapping[action]['id']]=1\n",
    "            R[action,state]=mapping[action]['cost']\n",
    "    policy=policy_iteration(P,R,STATES)\n",
    "    return policy,df_state_details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### EXTRACTS (LAT,LONG) From Policy\n",
    "### ALL PAIRS PATH\n",
    "def extract_from_policy(pollution_prediction,destination,N=16,alpha=0.3):\n",
    "    policy,df_state=return_policy(pollution_prediction,destination,N,alpha)\n",
    "    Path=[]\n",
    "    for index in range(len(policy)):\n",
    "        Tuples=df_state.iloc[index]['directions'][policy[index][0]]['Tuples_list']\n",
    "        for tup in Tuples:\n",
    "            Path.append(tup)\n",
    "    return policy,Path,df_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALL PAIRS\n",
    "def processing_output(pollution_pred,dest,N=16):\n",
    "    policy,path,df_state=extract_from_policy(pollution_pred,dest)\n",
    "    \n",
    "    mappings={0:{'v':1,'u':0},\n",
    "              1:{'v':1,'u':1},\n",
    "              2:{'v':0,'u':1},\n",
    "              3:{'v':-1,'u':1},\n",
    "              4:{'v':-1,'u':0},\n",
    "              5:{'v':-1,'u':-1},\n",
    "              6:{'v':0,'u':-1},\n",
    "              7:{'v':1,'u':-1}}\n",
    "\n",
    "\n",
    "    U=np.array(list(map(lambda e:mappings[e]['u'],list(policy.flatten())))).reshape(N,N)\n",
    "    V=np.array(list(map(lambda e:mappings[e]['v'],list(policy.flatten())))).reshape(N,N)\n",
    "\n",
    "    X=df_state.Latitudes.values.reshape(N,N)\n",
    "    Y=df_state.Longitudes.values.reshape(N,N)\n",
    "\n",
    "    fig=plt.figure(figsize=(15,9))\n",
    "    ax=fig.add_subplot(111)\n",
    "    ax.quiver(X,Y,U,V)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=180)\n",
    "    ############################################################\n",
    "    for i,(x,y) in enumerate(zip(X.flatten(),Y.flatten())):\n",
    "            ax.annotate(str(i),(x,y),color='blue',rotation=180)\n",
    "\n",
    "    fig.savefig('./Outputs/path.png')\n",
    "    plt.close()\n",
    "\n",
    "    plain = PIL.Image.open(\"./Outputs/path.png\")\n",
    "    plain=plain.rotate(-180)\n",
    "    plain.save(\"./Outputs/path.png\")\n",
    "\n",
    "    Latitudes=[p[0] for p in path]\n",
    "\n",
    "    Longitudes=[p[1] for p in path]\n",
    "\n",
    "    df_path=pd.DataFrame(list(zip(Latitudes,Longitudes)),columns=['Latitudes','Longitudes'])\n",
    "\n",
    "    df_path.to_csv('All_Pair_Paths.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_source_path_deterministic(source,destination,pollution_prediction,alpha=0.3,N=16): \n",
    "    policy,df_state=return_policy(pollution_prediction,destination,N,alpha)    \n",
    "    SOURCE_STATE=np.argmin(df_state[['Latitudes','Longitudes']].apply(lambda tup: euclidean_distance(tup[0],tup[1],source[0],source[1]),axis=1).values)\n",
    "    dest_lat,dest_long=get_lat_long(destination)\n",
    "    GOAL_STATE=np.argmin(df_state[['Latitudes','Longitudes']].apply(lambda tup: euclidean_distance(tup[0],tup[1],dest_lat,dest_long),axis=1).values)\n",
    "    Path=[]\n",
    "    state=SOURCE_STATE\n",
    "    while state!=GOAL_STATE:\n",
    "        Tuples=df_state.iloc[state]['directions'][policy[state][0]]['Tuples_list']\n",
    "        for tup in Tuples:\n",
    "            Path.append(tup)\n",
    "        state=df_state.iloc[state]['directions'][policy[state][0]]['id']\n",
    "    \n",
    "    return Path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_source_path_probabilistic_30(source,destination,pollution_prediction,alpha=0.3,N=16): \n",
    "    policy,df_state=return_policy(pollution_prediction,destination,N,alpha)    \n",
    "    SOURCE_STATE=np.argmin(df_state[['Latitudes','Longitudes']].apply(lambda tup: euclidean_distance(tup[0],tup[1],source[0],source[1]),axis=1).values)\n",
    "    dest_lat,dest_long=get_lat_long(destination)\n",
    "    GOAL_STATE=np.argmin(df_state[['Latitudes','Longitudes']].apply(lambda tup: euclidean_distance(tup[0],tup[1],dest_lat,dest_long),axis=1).values)\n",
    "    Path=[]\n",
    "    state=SOURCE_STATE\n",
    "    while state!=GOAL_STATE:\n",
    "        if np.random.random()<=0.7:\n",
    "            action=policy[state][0]\n",
    "        else:\n",
    "            action=np.random.randint(0,8)\n",
    "            \n",
    "        Tuples=df_state.iloc[state]['directions'][action]['Tuples_list']\n",
    "        for tup in Tuples:\n",
    "            Path.append(tup)\n",
    "        state=df_state.iloc[state]['directions'][action]['id']\n",
    "    \n",
    "    return Path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_source_path_probabilistic_50(source,destination,pollution_prediction,alpha=0.3,N=16): \n",
    "    policy,df_state=return_policy(pollution_prediction,destination,N,alpha)    \n",
    "    SOURCE_STATE=np.argmin(df_state[['Latitudes','Longitudes']].apply(lambda tup: euclidean_distance(tup[0],tup[1],source[0],source[1]),axis=1).values)\n",
    "    dest_lat,dest_long=get_lat_long(destination)\n",
    "    GOAL_STATE=np.argmin(df_state[['Latitudes','Longitudes']].apply(lambda tup: euclidean_distance(tup[0],tup[1],dest_lat,dest_long),axis=1).values)\n",
    "    Path=[]\n",
    "    state=SOURCE_STATE\n",
    "    while state!=GOAL_STATE:\n",
    "        if np.random.random()<=0.5:\n",
    "            action=policy[state][0]\n",
    "        else:\n",
    "            action=np.random.randint(0,8)\n",
    "            \n",
    "        Tuples=df_state.iloc[state]['directions'][action]['Tuples_list']\n",
    "        for tup in Tuples:\n",
    "            Path.append(tup)\n",
    "        state=df_state.iloc[state]['directions'][action]['id']\n",
    "    \n",
    "    return Path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhijit/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/abhijit/.local/lib/python3.6/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START STATE\n",
      "240\n",
      "23.565774\n",
      "87.269568\n",
      "[(23.565774, 87.269568), (23.565259833333336, 87.27043608333334), (23.564745666666667, 87.27130416666668), (23.564231499999998, 87.27217225000001), (23.563717333333333, 87.27304033333334)]\n",
      "REACHED STATE\n",
      "225\n",
      "23.563717333333333\n",
      "87.27304033333334\n",
      "START STATE\n",
      "225\n",
      "23.563717333333333\n",
      "87.27304033333334\n",
      "[(23.563717333333333, 87.27304033333334), (23.563203166666668, 87.27390841666667), (23.562689, 87.2747765), (23.562174833333334, 87.27564458333335), (23.56166066666667, 87.27651266666668)]\n",
      "REACHED STATE\n",
      "210\n",
      "23.56166066666667\n",
      "87.27651266666668\n",
      "START STATE\n",
      "210\n",
      "23.56166066666667\n",
      "87.27651266666668\n",
      "[(23.56166066666667, 87.27651266666668), (23.5611465, 87.27738075), (23.560632333333334, 87.27824883333335), (23.56011816666667, 87.27911691666668), (23.559604, 87.27998500000001)]\n",
      "REACHED STATE\n",
      "195\n",
      "23.559604\n",
      "87.27998500000001\n",
      "START STATE\n",
      "195\n",
      "23.559604\n",
      "87.27998500000001\n",
      "[(23.559604, 87.27998500000001), (23.559089833333335, 87.28085308333334), (23.55857566666667, 87.28172116666667), (23.5580615, 87.28258925), (23.557547333333336, 87.28345733333333)]\n",
      "REACHED STATE\n",
      "180\n",
      "23.557547333333336\n",
      "87.28345733333333\n",
      "START STATE\n",
      "180\n",
      "23.557547333333336\n",
      "87.28345733333333\n",
      "[(23.557547333333336, 87.28345733333333), (23.557547333333336, 87.28432541666666), (23.557547333333336, 87.28519349999999), (23.557547333333336, 87.28606158333334), (23.557547333333336, 87.28692966666667)]\n",
      "REACHED STATE\n",
      "181\n",
      "23.557547333333336\n",
      "87.28692966666667\n",
      "START STATE\n",
      "181\n",
      "23.557547333333336\n",
      "87.28692966666667\n",
      "[(23.557547333333336, 87.28692966666667), (23.55703316666667, 87.28779775), (23.556519, 87.28866583333334), (23.556004833333333, 87.28953391666667), (23.555490666666667, 87.290402)]\n",
      "REACHED STATE\n",
      "166\n",
      "23.555490666666667\n",
      "87.290402\n"
     ]
    }
   ],
   "source": [
    "arr=np.array([\n",
    "    [1,2,1,3],\n",
    "    [2,1,1,3],\n",
    "    [1,1,1,2],\n",
    "    [2,2,3,3]\n",
    "],dtype=np.uint8)\n",
    "source=23.565774, 87.269568\n",
    "Path=get_single_source_path_deterministic(source,'XYZ',arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Latitudes=[p[0] for p in Path]\n",
    "\n",
    "Longitudes=[p[1] for p in Path]\n",
    "\n",
    "df_path=pd.DataFrame(list(zip(Latitudes,Longitudes)),columns=['Latitudes','Longitudes'])\n",
    "\n",
    "df_path.to_csv('Single_Pair_Path_deterministic.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhijit/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/abhijit/.local/lib/python3.6/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "processing_output(arr,'XYZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
